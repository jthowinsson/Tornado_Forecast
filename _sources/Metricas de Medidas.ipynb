{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Modelo                | MAPE     | RMSE      | R²       | Ljung-Box p-value | Jarque-Bera p-value |\n",
    "|-----------------------|----------|-----------|----------|-------------------|---------------------|\n",
    "| K-NN                  | 0.037967 | 0.143212  | 0.082747 | 0.224391          | 0.0                 |\n",
    "| Linear Regression     | 1.989183 | 13.468950 | 0.657471 | 0.999805          | 0.0                 |\n",
    "| Ridge Regression      | 1.989183 | 13.468953 | 0.657470 | 0.999805          | 0.0                 |\n",
    "| Lasso Regression      | 1.925378 | 13.480709 | 0.656872 | 0.999793          | 0.0                 |\n",
    "| Random Forest Regressor | —        | —         | —        | —                 | —                   |\n",
    "| XGBoost Regressor     | —        | —         | —        | —                 | —                   |\n",
    "| SVR                   | —        | —         | —        | —                 | —                   |                  |       |       |          |                         |                         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, explained_variance_score, mean_squared_error, mean_squared_log_error\n",
    "\n",
    "# Seleccionar las características y la variable objetivo\n",
    "X = tornados_target[['mag', 'slat', 'slon', 'elat', 'elon', 'len', 'wid','fat','f1', 'f2', 'f3', 'f4']]\n",
    "y = df['mortality']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=66)\n",
    "\n",
    "# Ahora puedes crear el modelo sin el error\n",
    "knn = KNeighborsRegressor(n_neighbors=81)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "score = knn.score(X_test, y_test)\n",
    "\n",
    "# Cálculo de métricas\n",
    "r2_valid = r2_score(y_test, y_pred)\n",
    "mae_valid = mean_absolute_error(y_test, y_pred)\n",
    "evs_valid = explained_variance_score(y_test, y_pred, multioutput='uniform_average')\n",
    "rmse_valid = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "rmsle_valid = np.sqrt(mean_squared_log_error(y_test, np.abs(y_pred)))  # Evitar valores negativos\n",
    "\n",
    "# Prueba de Ljung-Box (residuos deben estar disponibles)\n",
    "residuos = y_test - y_pred\n",
    "ljung_box_test = acorr_ljungbox(residuos, lags=[10], return_df=True)\n",
    "\n",
    "# Prueba de Jarque-Bera\n",
    "jb_test = jarque_bera(residuos)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print('R2 Valid:', r2_valid)\n",
    "print('EVS Valid:', evs_valid)\n",
    "print('MAE Valid:', mae_valid)\n",
    "print('RMSE Valid:', rmse_valid)\n",
    "print('RMSLE Valid:', rmsle_valid)\n",
    "print('\\nLjung-Box Test:')\n",
    "print(ljung_box_test)\n",
    "print('\\nJarque-Bera Test:')\n",
    "print(f'Estadístico: {jb_test[0]}, p-valor: {jb_test[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2 Valid: 0.08274669092769293\n",
    "EVS Valid: 0.08327231375666555\n",
    "MAE Valid: 0.037966521313441075\n",
    "RMSE Valid: 0.1432116600452836\n",
    "RMSLE Valid: 0.09951451645787435\n",
    "\n",
    "Ljung-Box Test:\n",
    "     lb_stat  lb_pvalue\n",
    "10  12.98715   0.224391\n",
    "\n",
    "Jarque-Bera Test:\n",
    "Estadístico: 973530.9803433096, p-valor: 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión Linela Ridge and Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir X y y (asegúrate de que ya tienes estas variables previamente definidas)\n",
    "X = df[['mag', 'slat', 'slon', 'elat', 'elon', 'len', 'wid','fat','f1', 'f2', 'f3', 'f4','loss']]\n",
    "y = df['inj']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear y ajustar el modelo de regresión lineal\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "ridge = Ridge(alpha=0.1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, explained_variance_score, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir modelos\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso Regression': Lasso(alpha=0.1),\n",
    "    'Ridge Regression': Ridge(alpha=0.1)\n",
    "}\n",
    "\n",
    "# DataFrame para almacenar resultados\n",
    "results = []\n",
    "\n",
    "# Evaluar cada modelo\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Cálculo de métricas\n",
    "    r2_valid = r2_score(y_test, y_pred)\n",
    "    mae_valid = mean_absolute_error(y_test, y_pred)\n",
    "    evs_valid = explained_variance_score(y_test, y_pred, multioutput='uniform_average')\n",
    "    rmse_valid = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmsle_valid = np.sqrt(mean_squared_log_error(y_test, np.abs(y_pred)))  # Evitar valores negativos\n",
    "    \n",
    "    # Prueba de Ljung-Box\n",
    "    residuos = y_test - y_pred\n",
    "    ljung_box_test = acorr_ljungbox(residuos, lags=[10], return_df=True)\n",
    "    \n",
    "    # Prueba de Jarque-Bera\n",
    "    jb_test = jarque_bera(residuos)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results.append([\n",
    "        name, mae_valid, rmse_valid, r2_valid,\n",
    "        ljung_box_test['lb_pvalue'].values[0],\n",
    "        jb_test[1]\n",
    "    ])\n",
    "\n",
    "# Convertir resultados a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=[\n",
    "    'Modelo', 'MAPE', 'RMSE', 'R^2', 'Ljung-Box p-value', 'Jarque-Bera p-value'\n",
    "])\n",
    "\n",
    "# Mostrar resultados\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo      MAPE       RMSE       R^2  Ljung-Box p-value  \\\n",
    "0  Linear Regression  1.989183  13.468950  0.657471           0.999805   \n",
    "1   Lasso Regression  1.925378  13.480709  0.656872           0.999793   \n",
    "2   Ridge Regression  1.989183  13.468953  0.657470           0.999805   \n",
    "\n",
    "   Jarque-Bera p-value  \n",
    "0                  0.0  \n",
    "1                  0.0  \n",
    "2                  0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Modelo                         | precision | recall  | accuracy | f₁-score | AUC     |\n",
    "|--------------------------------|-----------|---------|----------|----------|---------|\n",
    "| Clasificación Bayesiana        | 0.22      | 0.66    | 0.9094   | 0.33     | —       |\n",
    "| K-NN                           | 1.00      | 0.31    | 0.9842   | 0.47     | —       |\n",
    "| L1/L2 Penalty Logistic Regression | 0.69 (L1) | 0.33 (L1) | 0.9092 (L1) | 0.44 (L1) | —       |\n",
    "|                                | 0.53 (L2) | 0.10 (L2) | 0.8906 (L2) | 0.16 (L2) | —       |\n",
    "| Random Forest                  | 1.00      | 1.00    | 1.0000   | 1.00     | —       |\n",
    "| XGBoost                        | 1.00      | 1.00    | 1.0000   | 1.00     | —       |\n",
    "| SVM                            | 0.96      | 0.12    | 0.9700   | 0.21     | —       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGboost and Ramdon Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "ruta = r'C:/Users/wmanj/OneDrive/Escritorio/MACHINELEARNING/tornados.csv'  \n",
    "df = pd.read_csv(ruta) \n",
    "df['loss'] = df['loss'].replace(0, pd.NA)\n",
    "df['loss'] = df['loss'].interpolate(method='linear')\n",
    "df['mag'] = df['mag'].fillna(df['mag'].mean())\n",
    "df.isnull().sum()\n",
    "\n",
    "# Crear la columna 'mortality' en el DataFrame original\n",
    "df['mortality'] = df['fat'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "# Renombrar el DataFrame a 'mortality_target'\n",
    "mortality_target = df\n",
    "import numpy as np\n",
    "\n",
    "# Crear la columna 'mortality' con 0 si 'fat' es 0, y 1 si 'fat' es mayor que 0\n",
    "df['mortality'] = np.where(df['fat'] == 0, 0, 1)\n",
    "\n",
    "# Contar la cantidad de ceros y unos\n",
    "print(\"Cantidad de ceros:\", (df['mortality'] == 0).sum())\n",
    "print(\"Cantidad de unos:\", (df['mortality'] == 1).sum())\n",
    "\n",
    "# Asignar el DataFrame modificado a 'tornados.target'\n",
    "tornados_target = df\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = tornados_target[['om', 'yr', 'mo', 'dy', 'stf', 'mag', 'inj', 'fat', 'loss', 'slat', 'slon', 'elat', 'elon', 'len', 'wid', 'ns', 'sn', 'f1', 'f2', 'f3', 'f4']]\n",
    "y = df['mortality']\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Crear el modelo XGBoost\n",
    "xgboost_model = xgb.XGBClassifier(random_state=0)\n",
    "forest = RandomForestClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    log_loss, \n",
    "    roc_auc_score, \n",
    "    confusion_matrix, \n",
    "    classification_report\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def generar_datos(n_samples=500, n_features=5, ruido=0.3, seed=42):\n",
    "    \"\"\"Genera datos sintéticos para clasificación\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    X = np.random.rand(n_samples, n_features)\n",
    "    pesos = np.array([1.5, -2, 0.5, 3, -1])\n",
    "    y = (X @ pesos + np.random.normal(0, ruido, n_samples) > 0).astype(int)\n",
    "    return X, y\n",
    "\n",
    "def evaluar_modelo(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Evalúa un modelo de clasificación con múltiples métricas\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    metricas = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'LogLoss': log_loss(y_test, y_pred_proba),\n",
    "        'ROC AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "        'Confusion Matrix': confusion_matrix(y_test, y_pred).tolist(),\n",
    "        'Cross-Val Score': np.mean(cross_val_score(model, X_train, y_train, cv=5))\n",
    "    }\n",
    "    \n",
    "    # Pruebas estadísticas de residuos\n",
    "    residuos = y_test - y_pred\n",
    "    \n",
    "    try:\n",
    "        metricas['Ljung-Box p-value'] = acorr_ljungbox(residuos, lags=[10], return_df=True)['lb_pvalue'].values[0]\n",
    "    except:\n",
    "        metricas['Ljung-Box p-value'] = np.nan\n",
    "    \n",
    "    try:\n",
    "        metricas['Jarque-Bera p-value'] = jarque_bera(residuos)[1]\n",
    "    except:\n",
    "        metricas['Jarque-Bera p-value'] = np.nan\n",
    "    \n",
    "    return metricas\n",
    "\n",
    "def comparar_modelos(X, y, test_size=0.3, seed=42):\n",
    "    \"\"\"Compara múltiples modelos de clasificación\"\"\"\n",
    "    # Normalizar datos\n",
    "    scaler = StandardScaler()\n",
    "    X_escalado = scaler.fit_transform(X)\n",
    "    \n",
    "    # Dividir datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_escalado, y, test_size=test_size, random_state=seed\n",
    "    )\n",
    "    \n",
    "    # Definir modelos\n",
    "    modelos = {\n",
    "        'Random Forest': RandomForestClassifier(random_state=seed),\n",
    "        'XGBoost': xgb.XGBClassifier(\n",
    "            use_label_encoder=False, \n",
    "            eval_metric='logloss', \n",
    "            random_state=seed\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Resultados\n",
    "    resultados = {}\n",
    "    for nombre, modelo in modelos.items():\n",
    "        resultados[nombre] = evaluar_modelo(modelo, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Convertir a DataFrame\n",
    "    df_resultados = pd.DataFrame.from_dict(resultados, orient='index')\n",
    "    \n",
    "    return df_resultados\n",
    "\n",
    "# Ejecutar análisis\n",
    "X, y = generar_datos()\n",
    "resultados = comparar_modelos(X, y)\n",
    "print(\"Resultados de Comparación de Modelos:\\n\")\n",
    "print(resultados)\n",
    "\n",
    "# Exportar resultados\n",
    "resultados.to_csv('resultados_modelos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de Comparación de Modelos:\n",
    "\n",
    "               Accuracy   LogLoss   ROC AUC      Confusion Matrix  \\\n",
    "Random Forest  0.893333  0.235760  0.962262  [[17, 15], [1, 117]]   \n",
    "XGBoost        0.893333  0.241258  0.961335  [[19, 13], [3, 115]]   \n",
    "\n",
    "               Cross-Val Score  Ljung-Box p-value  Jarque-Bera p-value  \n",
    "Random Forest         0.891429           0.270149         1.047062e-59  \n",
    "XGBoost               0.900000           0.878839         1.114084e-56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Repetimos la separación si no está hecha\n",
    "X = df_ml.drop('mortality', axis=1)\n",
    "y = df_ml['mortality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=101, stratify=y\n",
    ")\n",
    "\n",
    "# 2. Aplicar SMOTE solo al conjunto de entrenamiento\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Distribución después de SMOTE:\")\n",
    "print(y_train_sm.value_counts(normalize=True))\n",
    "\n",
    "# 3. Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_sm_scaled = scaler.fit_transform(X_train_sm)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Entrenar modelo con cronómetro ⏱️\n",
    "start_time = time.time()\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train_sm_scaled, y_train_sm)\n",
    "tiempo_entrenamiento = time.time() - start_time\n",
    "\n",
    "# 5. Predecir sobre el conjunto de prueba (sin SMOTE)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 6. Evaluar resultados\n",
    "print(\"\\n🔍 Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n📊 Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n📋 Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# 7. Guardar métricas en DataFrame\n",
    "resultados_bayes_smote = pd.DataFrame({\n",
    "    'Modelo': ['Naive Bayes (con SMOTE)'],\n",
    "    'Accuracy': [round(accuracy_score(y_test, y_pred), 4)],\n",
    "    'Precision': [round(precision_score(y_test, y_pred), 4)],\n",
    "    'Recall': [round(recall_score(y_test, y_pred), 4)],\n",
    "    'F1-score': [round(f1_score(y_test, y_pred), 4)],\n",
    "    'AUC': [round(roc_auc_score(y_test, y_prob), 4)],\n",
    "    'CPU time (s)': [round(tiempo_entrenamiento, 4)]\n",
    "})\n",
    "\n",
    "# 8. Mostrar resultados\n",
    "display(resultados_bayes_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribución después de SMOTE:\n",
    "mortality\n",
    "0    0.5\n",
    "1    0.5\n",
    "Name: proportion, dtype: float64\n",
    "\n",
    "🔍 Accuracy: 0.9094412331406551\n",
    "\n",
    "📊 Matriz de confusión:\n",
    " [[11044   982]\n",
    " [  146   284]]\n",
    "\n",
    "📋 Reporte de clasificación:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.99      0.92      0.95     12026\n",
    "           1       0.22      0.66      0.33       430\n",
    "\n",
    "    accuracy                           0.91     12456\n",
    "   macro avg       0.61      0.79      0.64     12456\n",
    "weighted avg       0.96      0.91      0.93     12456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Matriz de Confusión:\n",
      " [[12024     2]\n",
      " [  378    52]]\n",
      "\n",
      "📋 Reporte de Clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     12026\n",
      "           1       0.96      0.12      0.21       430\n",
      "\n",
      "    accuracy                           0.97     12456\n",
      "   macro avg       0.97      0.56      0.60     12456\n",
      "weighted avg       0.97      0.97      0.96     12456\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>CPU time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC (con calibración)</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.919</td>\n",
       "      <td>3.4848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Modelo  Accuracy  Precision  Recall  F1-score    AUC  \\\n",
       "0  LinearSVC (con calibración)    0.9695      0.963  0.1209    0.2149  0.919   \n",
       "\n",
       "   CPU time (s)  \n",
       "0        3.4848  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Medir tiempo de entrenamiento\n",
    "inicio = time.time()\n",
    "\n",
    "# Entrenamos con LinearSVC (no tiene predict_proba, así que usamos CalibratedClassifierCV)\n",
    "linear_svc_base = LinearSVC(random_state=42, max_iter=10000)\n",
    "calibrated_svc = CalibratedClassifierCV(linear_svc_base, cv=5)\n",
    "calibrated_svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "fin = time.time()\n",
    "tiempo_entrenamiento = fin - inicio\n",
    "\n",
    "# Predecir\n",
    "y_pred_linear_svc = calibrated_svc.predict(X_test_scaled)\n",
    "y_prob_linear_svc = calibrated_svc.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Guardar métricas\n",
    "resultados_linear_svc = pd.DataFrame({\n",
    "    'Modelo': ['LinearSVC (con calibración)'],\n",
    "    'Accuracy': [round(accuracy_score(y_test, y_pred_linear_svc), 4)],\n",
    "    'Precision': [round(precision_score(y_test, y_pred_linear_svc), 4)],\n",
    "    'Recall': [round(recall_score(y_test, y_pred_linear_svc), 4)],\n",
    "    'F1-score': [round(f1_score(y_test, y_pred_linear_svc), 4)],\n",
    "    'AUC': [round(roc_auc_score(y_test, y_prob_linear_svc), 4)],\n",
    "    'CPU time (s)': [round(tiempo_entrenamiento, 4)]\n",
    "})\n",
    "\n",
    "# Verificar matriz y reporte si quieres\n",
    "print(\"📊 Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred_linear_svc))\n",
    "print(\"\\n📋 Reporte de Clasificación:\\n\", classification_report(y_test, y_pred_linear_svc))\n",
    "\n",
    "display(resultados_linear_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 and L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Convertir 'inj' a binario si no lo es (ej: 0=no heridos, 1=heridos)\n",
    "y_binary = (y > 0).astype(int)  # Ajusta según tu contexto\n",
    "\n",
    "# Dividir datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo con penalización L1 (Lasso) o L2 (Ridge)\n",
    "model_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1.0).fit(X_train, y_train)  # L1\n",
    "model_l2 = LogisticRegression(penalty='l2', solver='liblinear', C=1.0).fit(X_train, y_train)  # L2\n",
    "\n",
    "# Evaluación\n",
    "print(\"Precisión (L1):\", accuracy_score(y_test, model_l1.predict(X_test)))\n",
    "print(\"Reporte (L1):\\n\", classification_report(y_test, model_l1.predict(X_test)))\n",
    "print(\"Precisión (L2):\", accuracy_score(y_test, model_l2.predict(X_test)))\n",
    "print(\"Reporte (L2):\\n\", classification_report(y_test, model_l2.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisión (L1): 0.9091636945920373\n",
    "Reporte (L1):\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.92      0.98      0.95     12219\n",
    "           1       0.69      0.33      0.44      1520\n",
    "\n",
    "    accuracy                           0.91     13739\n",
    "   macro avg       0.81      0.65      0.70     13739\n",
    "weighted avg       0.90      0.91      0.89     13739\n",
    "\n",
    "Precisión (L2): 0.8906033918043526\n",
    "Reporte (L2):\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.99      0.94     12219\n",
    "           1       0.53      0.10      0.16      1520\n",
    "\n",
    "    accuracy                           0.89     13739\n",
    "   macro avg       0.71      0.54      0.55     13739\n",
    "weighted avg       0.86      0.89      0.86     13739"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Seleccionar las características y la variable objetivo\n",
    "X = tornados_target[['mag', 'slat', 'slon', 'elat', 'elon', 'len', 'wid', 'fat', 'f1', 'f2', 'f3', 'f4']]\n",
    "y = df['mortality']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101, stratify=y)\n",
    "\n",
    "# Estándarizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Entrenar el modelo y medir el tiempo de entrenamiento\n",
    "start_time = time.time()\n",
    "knn = KNeighborsClassifier(n_neighbors=81)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "y_prob = knn.predict_proba(X_test)[:, 1]  # Probabilidades de la clase positiva\n",
    "end_time = time.time()\n",
    "\n",
    "# Medir el tiempo de entrenamiento\n",
    "tiempo_entrenamiento = end_time - start_time\n",
    "\n",
    "# Evaluar resultados\n",
    "print(\"\\n🔍 Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n📊 Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n📋 Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Guardar métricas en DataFrame\n",
    "resultados_bayes_smote = pd.DataFrame({\n",
    "    'Modelo': ['K-Neighbors (Clasificador)'],\n",
    "    'Accuracy': [round(accuracy_score(y_test, y_pred), 4)],\n",
    "    'Precision': [round(precision_score(y_test, y_pred), 4)],\n",
    "    'Recall': [round(recall_score(y_test, y_pred), 4)],\n",
    "    'F1-score': [round(f1_score(y_test, y_pred), 4)],\n",
    "    'AUC': [round(roc_auc_score(y_test, y_prob), 4)],\n",
    "    'CPU time (s)': [round(tiempo_entrenamiento, 4)]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔍 Accuracy: 0.984180900621118\n",
    "\n",
    "📊 Matriz de confusión:\n",
    " [[20136     0]\n",
    " [  326   146]]\n",
    "\n",
    "📋 Reporte de clasificación:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.98      1.00      0.99     20136\n",
    "           1       1.00      0.31      0.47       472\n",
    "\n",
    "    accuracy                           0.98     20608\n",
    "   macro avg       0.99      0.65      0.73     20608\n",
    "weighted avg       0.98      0.98      0.98     20608"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramdon Forest XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargar los datos\n",
    "ruta = r'C:/Users/wmanj/OneDrive/Escritorio/MACHINELEARNING/tornados.csv'  \n",
    "df = pd.read_csv(ruta) \n",
    "\n",
    "# Preprocesamiento de datos\n",
    "df['loss'] = df['loss'].replace(0, pd.NA)\n",
    "df['loss'] = df['loss'].interpolate(method='linear')\n",
    "df['mag'] = df['mag'].fillna(df['mag'].mean())\n",
    "df['mortality'] = np.where(df['fat'] == 0, 0, 1)\n",
    "\n",
    "# Dividir los datos\n",
    "X = df[['om', 'yr', 'mo', 'dy', 'stf', 'mag', 'inj', 'fat', 'loss', 'slat', 'slon', 'elat', 'elon', 'len', 'wid', 'ns', 'sn', 'f1', 'f2', 'f3', 'f4']]\n",
    "y = df['mortality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# Estándarización de los datos (si es necesario para algunos modelos)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Entrenar y evaluar el modelo XGBoost\n",
    "start_time = time.time()\n",
    "xgboost_model = xgb.XGBClassifier(random_state=0)\n",
    "xgboost_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgboost_model.predict(X_test)\n",
    "y_prob_xgb = xgboost_model.predict_proba(X_test)[:, 1]\n",
    "end_time = time.time()\n",
    "\n",
    "# Medir tiempo de entrenamiento\n",
    "xgboost_time = end_time - start_time\n",
    "\n",
    "# Evaluar XGBoost\n",
    "print(\"\\n📊 Evaluación de XGBoost:\")\n",
    "print(\"\\n🔍 Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"\\n📊 Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
    "print(\"\\n📋 Reporte de clasificación:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# Guardar métricas en DataFrame para XGBoost\n",
    "resultados_xgb = pd.DataFrame({\n",
    "    'Modelo': ['XGBoost'],\n",
    "    'Accuracy': [round(accuracy_score(y_test, y_pred_xgb), 4)],\n",
    "    'Precision': [round(precision_score(y_test, y_pred_xgb), 4)],\n",
    "    'Recall': [round(recall_score(y_test, y_pred_xgb), 4)],\n",
    "    'F1-score': [round(f1_score(y_test, y_pred_xgb), 4)],\n",
    "    'AUC': [round(roc_auc_score(y_test, y_prob_xgb), 4)],\n",
    "    'CPU time (s)': [round(xgboost_time, 4)]\n",
    "})\n",
    "\n",
    "# Entrenar y evaluar el modelo RandomForest\n",
    "start_time = time.time()\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred_rf = forest.predict(X_test)\n",
    "y_prob_rf = forest.predict_proba(X_test)[:, 1]\n",
    "end_time = time.time()\n",
    "\n",
    "# Medir tiempo de entrenamiento\n",
    "forest_time = end_time - start_time\n",
    "\n",
    "# Evaluar RandomForest\n",
    "print(\"\\n📊 Evaluación de Random Forest:\")\n",
    "print(\"\\n🔍 Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\n📊 Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\n📋 Reporte de clasificación:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Guardar métricas en DataFrame para Random Forest\n",
    "resultados_rf = pd.DataFrame({\n",
    "    'Modelo': ['Random Forest'],\n",
    "    'Accuracy': [round(accuracy_score(y_test, y_pred_rf), 4)],\n",
    "    'Precision': [round(precision_score(y_test, y_pred_rf), 4)],\n",
    "    'Recall': [round(recall_score(y_test, y_pred_rf), 4)],\n",
    "    'F1-score': [round(f1_score(y_test, y_pred_rf), 4)],\n",
    "    'AUC': [round(roc_auc_score(y_test, y_prob_rf), 4)],\n",
    "    'CPU time (s)': [round(forest_time, 4)]\n",
    "})\n",
    "\n",
    "# Unir los resultados de ambos modelos\n",
    "resultados_completos = pd.concat([resultados_xgb, resultados_rf], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📊 Evaluación de XGBoost:\n",
    "\n",
    "🔍 Accuracy: 1.0\n",
    "\n",
    "📊 Matriz de confusión:\n",
    " [[16781     0]\n",
    " [    0   393]]\n",
    "\n",
    "📋 Reporte de clasificación:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00     16781\n",
    "           1       1.00      1.00      1.00       393\n",
    "\n",
    "    accuracy                           1.00     17174\n",
    "   macro avg       1.00      1.00      1.00     17174\n",
    "weighted avg       1.00      1.00      1.00     17174\n",
    "\n",
    "\n",
    "📊 Evaluación de Random Forest:\n",
    "\n",
    "🔍 Accuracy: 1.0\n",
    "\n",
    "📊 Matriz de confusión:\n",
    " [[16781     0]\n",
    " [    0   393]]\n",
    "\n",
    "📋 Reporte de clasificación:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00     16781\n",
    "           1       1.00      1.00      1.00       393\n",
    "\n",
    "    accuracy                           1.00     17174\n",
    "   macro avg       1.00      1.00      1.00     17174\n",
    "weighted avg       1.00      1.00      1.00     17174"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
